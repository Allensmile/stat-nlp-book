{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Welcome to this interactive book on Statistical Natural Language Processing (NLP). NLP is a field that lies in the intersection of Computer Science, Artificial Intelligence (AI) and Linguistics with the goal to enable computers to solve tasks that require natural language _understanding_ and/or _generation_. Such tasks are omnipresent in most of our day-to-day life: think of [Machine Translation](https://www.bing.com/translator/), Automatic [Question Answering](https://www.youtube.com/watch?v=WFR3lOm_xhE) or even basic [Search](https://www.google.co.uk). All these tasks require the computer to process language in one way or another. But even if you ignore these practical applications, many people consider language to be at the heart of human intelligence, and this makes NLP (and it's more linguistically motivated cousin, [Computional Linguistics](http://en.wikipedia.org/wiki/Computational_linguistics)), important for its role in AI alone.              \n",
    "\n",
    "### Statistical NLP\n",
    "NLP is a vast field with beginnings dating back to TODO, and it of course is difficult to give a full account of every aspect of NLP. Hence, this book focusses on a sub-field of NLP termed Statistical NLP (SNLP). In SNLP computers aren't directly programmed to process language; instead, they _learn_ how language should be processed based on the _statistics_ of a corpus of natural language. For example, a statistical machine translation system's behaviour is affected by the statistics of a _parallel_ corpus where each document in one language is paired with its translation in another. This approach has been dominating NLP research for almost two decades now, and has seen widespread in industry too. Notice that while Statistics and Machine Learning are, in general, quite different fields, for the purposes of this book we will mostly identify Statistical NLP with Machine Learning-based NLP.      \n",
    "\n",
    "### Structure of this Book\n",
    "We think that to understand and apply SNLP in practice one needs knowledge of the following:\n",
    "\n",
    "  * Tasks (e.g. Machine Translation, Syntactic Parsing)\n",
    "  * Methods & Frameworks (e.g. Structured Prediction, Discriminative Training, Linear Chain models, Representation Learning)\n",
    "  * Implementations (e.g. NLP data structures, efficient dynamic programming)\n",
    "   \n",
    "The book is hence organized along these three dimensions. For each dimension we provide a series of chapters that be understood in isolation as much as possible. You can read the book linearly by following the Task axis. Each task chapter will feature links to methods useful for the tasks, and implementation details that apply in the given context.   \n",
    "\n",
    "### Interaction\n",
    "\n",
    "The best way to learn language processing with computers is \n",
    "to process language with computers, and hence this book features interactive \n",
    "code blocks that we use to show NLP in practice, and that you can use \n",
    "to test and investigate methods and language. We use the Python language throughout this book because it offers a large number of relevant libraries and it easy to learn.\n",
    "\n",
    "If you have programmed before, odds are you have used processed language in one way or another. \n",
    "For example, you have probably accessed substrings before.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
