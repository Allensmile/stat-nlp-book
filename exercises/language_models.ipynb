{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Model Exercises\n",
    "In these exercises you will extend and develop language models. We will use the code from the notes, but within a python package [`lm`](http://localhost:8888/edit/statnlpbook/lm.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Setup 1</font>: Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-21T16:59:18.569772",
     "start_time": "2016-10-21T16:59:18.552156"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import sys, os\n",
    "_snlp_book_dir = \"..\"\n",
    "sys.path.append(_snlp_book_dir) \n",
    "from statnlpbook.lm import *\n",
    "from statnlpbook.ohhla import *\n",
    "# %cd .. \n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 6.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!---\n",
    "Latex Macros\n",
    "-->\n",
    "$$\n",
    "\\newcommand{\\prob}{p}\n",
    "\\newcommand{\\vocab}{V}\n",
    "\\newcommand{\\params}{\\boldsymbol{\\theta}}\n",
    "\\newcommand{\\param}{\\theta}\n",
    "\\DeclareMathOperator{\\perplexity}{PP}\n",
    "\\DeclareMathOperator{\\argmax}{argmax}\n",
    "\\newcommand{\\train}{\\mathcal{D}}\n",
    "\\newcommand{\\counts}[2]{\\#_{#1}(#2) }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Setup 2</font>: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-21T16:59:18.613748",
     "start_time": "2016-10-21T16:59:18.575886"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "docs = load_all_songs(\"../data/ohhla/train/www.ohhla.com/anonymous/j_live/\")\n",
    "assert len(docs) == 50, \"Your ohhla corpus is corrupted, please download it again!\"\n",
    "trainDocs, testDocs = docs[:len(docs)//2], docs[len(docs)//2:] \n",
    "train = words(trainDocs)\n",
    "test = words(testDocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Task 1</font>: Optimal Pseudo Count \n",
    "\n",
    "Plot the perplexity for laplace smoothing on the given data as a function of alpha in the interval [0.001, 0.1] in steps by 0.001. Is it fair to assume that this is a convex function? Write a method that finds the optimal pseudo count `alpha` number for [laplace smoothing](https://github.com/uclmr/stat-nlp-book/blob/python/statnlpbook/lm.py#L180) for the given data up to some predefined numerical precision `epsilon` under the assumption that the perplexity is a convex function of alpha. How often did you have to call `perplexity` to find the optimum?\n",
    "\n",
    "Tips:\n",
    "<font color='white'>\n",
    "You don't need 1st or 2nd order derivatives in this case, only the gradient descent direction. Think about recursively slicing up the problem.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-21T16:59:19.151308",
     "start_time": "2016-10-21T16:59:18.615252"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmoAAAFwCAYAAAAId1cfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUAMAGNT/B1u4q25Tz3yEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113acd0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "oov_train = inject_OOVs(train)\n",
    "oov_vocab = set(oov_train)\n",
    "oov_test = replace_OOVs(oov_vocab, test)\n",
    "bigram = NGramLM(oov_train,2)\n",
    "\n",
    "interval = [x/1000.0 for x in range(1, 100, 1)]\n",
    "perplexity_at_1 = perplexity(LaplaceLM(bigram, alpha=1.0), oov_test)\n",
    "\n",
    "def plot_perplexities(interval):\n",
    "    \"\"\"Plots the perplexity of LaplaceLM for every alpha in interval.\"\"\"\n",
    "    perplexities = [0.0 for alpha in interval]  # todo\n",
    "    plt.plot(interval, perplexities)\n",
    "    \n",
    "def find_optimal(low, high, epsilon=1e-6):\n",
    "    \"\"\"Returns the optimal pseudo count alpha within the interval [low, high] and the perplexity.\"\"\"\n",
    "    print(high, low)\n",
    "    if high - low < epsilon:\n",
    "        return 0.0  # todo\n",
    "    else:\n",
    "        return 0.0  # todo\n",
    "\n",
    "plot_perplexities(interval)        \n",
    "find_optimal(0.0, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Task 2</font>: Sanity Check LM\n",
    "Implement a method that tests whether a language model provides a valid probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-21T16:59:19.237379",
     "start_time": "2016-10-21T16:59:19.153304"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0647115579930855\n"
     ]
    }
   ],
   "source": [
    "def sanity_check(lm, *history):\n",
    "    \"\"\"Throws an AssertionError if lm does not define a valid probability distribution for all words \n",
    "    in the vocabulary.\"\"\"  \n",
    "    probability_mass = 1.0  # todo\n",
    "    assert abs(probability_mass - 1.0) < 1e-6, probability_mass\n",
    "\n",
    "unigram = NGramLM(oov_train,1)\n",
    "stupid = StupidBackoff(bigram, unigram, 0.1)\n",
    "print(sum([stupid.probability(word, 'the') for word in stupid.vocab]))\n",
    "sanity_check(stupid, 'the')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Task 3</font>: Subtract Count LM\n",
    "Develop and implement a language model that subtracts a count $d\\in[0,1]$ from each non-zero count in the training set. Let's first formalize this:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\#_{w=0}(h_n) &= \\sum_{w \\in V} \\mathbf{1}[\\counts{\\train}{h_n,w} = 0]\\\\\n",
    "\\#_{w>0}(h_n) &= \\sum_{w \\in V} \\mathbf{1}[\\counts{\\train}{h_n,w} > 0]\\\\\n",
    "\\prob(w|h_n) &= \n",
    "\\begin{cases}\n",
    "\\frac{\\counts{\\train}{h_n,w} - d}{\\counts{\\train}{h_n}}  & \\mbox{if }\\counts{\\train}{h_n,w} > 0 \\\\\\\\\n",
    "\\frac{???}{\\counts{\\train}{h_n}} & \\mbox{otherwise}\n",
    "\\end{cases}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-21T16:59:19.337884",
     "start_time": "2016-10-21T16:59:19.240468"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SubtractCount(CountLM):        \n",
    "    def __init__(self, base_lm, d):\n",
    "        super().__init__(base_lm.vocab, base_lm.order)\n",
    "        self.base_lm = base_lm\n",
    "        self.d = d            \n",
    "        self._counts = base_lm._counts  # not good style since it is a protected member\n",
    "        self.vocab = base_lm.vocab\n",
    "\n",
    "    def counts(self, word_and_history):\n",
    "        if self._counts[word_and_history] > 0:\n",
    "            return 0.0  # todo\n",
    "        else:\n",
    "            return 0.0  # todo\n",
    "\n",
    "    def norm(self, history):\n",
    "        return self.base_lm.norm(history)    \n",
    "    \n",
    "subtract_lm = SubtractCount(unigram, 0.1)\n",
    "oov_prob = subtract_lm.probability(UNK, 'the')\n",
    "rest_prob = sum([subtract_lm.probability(word, 'the') for word in subtract_lm.vocab])\n",
    "print(oov_prob + rest_prob)\n",
    "sanity_check(subtract_lm, 'the')\n",
    "perplexity(subtract_lm, oov_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Task 4</font>: Normalisation of Stupid LM\n",
    "Develop and implement a version of the [stupid language model](https://github.com/uclmr/stat-nlp-book/blob/python/statnlpbook/lm.py#L205) that provides probabilities summing up to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-21T16:59:19.398354",
     "start_time": "2016-10-21T16:59:19.339446"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class StupidBackoffNormalized(LanguageModel):\n",
    "    def __init__(self, main, backoff, alpha):\n",
    "        super().__init__(main.vocab, main.order)\n",
    "        self.main = main\n",
    "        self.backoff = backoff\n",
    "        self.alpha = alpha               \n",
    "\n",
    "    def probability(self, word, *history):\n",
    "        return 0.0  # todo\n",
    "        \n",
    "less_stupid = StupidBackoffNormalized(bigram, unigram, 0.1)\n",
    "print(sum([less_stupid.probability(word, 'the') for word in less_stupid.vocab]))\n",
    "sanity_check(less_stupid, 'the')\n",
    "perplexity(less_stupid, oov_test)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
