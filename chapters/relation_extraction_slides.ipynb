{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'mpld3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f39a045497f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../statnlpbook/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mie\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtfutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relation_extraction.ipynb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Isabelle/Documents/UCLMR/stat-nlp-book/statnlpbook/util.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmpld3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'mpld3'"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"../statnlpbook/\")\n",
    "import util, ie,tfutil\n",
    "\n",
    "util.execute_notebook('relation_extraction.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<!---\n",
    "Latex Macros\n",
    "-->\n",
    "$$\n",
    "\\newcommand{\\Xs}{\\mathcal{X}}\n",
    "\\newcommand{\\Ys}{\\mathcal{Y}}\n",
    "\\newcommand{\\y}{\\mathbf{y}}\n",
    "\\newcommand{\\balpha}{\\boldsymbol{\\alpha}}\n",
    "\\newcommand{\\bbeta}{\\boldsymbol{\\beta}}\n",
    "\\newcommand{\\aligns}{\\mathbf{a}}\n",
    "\\newcommand{\\align}{a}\n",
    "\\newcommand{\\source}{\\mathbf{s}}\n",
    "\\newcommand{\\target}{\\mathbf{t}}\n",
    "\\newcommand{\\ssource}{s}\n",
    "\\newcommand{\\starget}{t}\n",
    "\\newcommand{\\repr}{\\mathbf{f}}\n",
    "\\newcommand{\\repry}{\\mathbf{g}}\n",
    "\\newcommand{\\x}{\\mathbf{x}}\n",
    "\\newcommand{\\prob}{p}\n",
    "\\newcommand{\\a}{\\alpha}\n",
    "\\newcommand{\\b}{\\beta}\n",
    "\\newcommand{\\vocab}{V}\n",
    "\\newcommand{\\params}{\\boldsymbol{\\theta}}\n",
    "\\newcommand{\\param}{\\theta}\n",
    "\\DeclareMathOperator{\\perplexity}{PP}\n",
    "\\DeclareMathOperator{\\argmax}{argmax}\n",
    "\\DeclareMathOperator{\\argmin}{argmin}\n",
    "\\newcommand{\\train}{\\mathcal{D}}\n",
    "\\newcommand{\\counts}[2]{\\#_{#1}(#2) }\n",
    "\\newcommand{\\length}[1]{\\text{length}(#1) }\n",
    "\\newcommand{\\indi}{\\mathbb{I}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Relation Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Motivation \n",
    "\n",
    "* The amount of available information is growing exponentially\n",
    "* Text contains a lot of information\n",
    "* Only some of information is relevant for each use case\n",
    "* How can we automatically make sense of information?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Information Extraction** addresses this\n",
    "\n",
    "[Alchemy information extraction demo](https://alchemy-language-demo.mybluemix.net/)\n",
    "\n",
    "[ReVerb demo](http://openie.allenai.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Subtasks of Information Extraction\n",
    "\n",
    "* **Document** Classification:\n",
    "    * Assign a label to each document, often representing the topic\n",
    "* **Named Entity Recognition**:\n",
    "    * Recognise boundaries of entities in text, e.g. \"New York\", \"New York Times\" \n",
    "* **Named Entity Classification**:\n",
    "    * Assign a type to each entity (e.g. \"New York\" -> location, \"New York Times\" -> media)\n",
    "* **Relation** Extraction:\n",
    "    * Recognise relatios between entities, e.g. \"S. Riedel reader-at UCL\"\n",
    "* **Temporal** Information Extraction:\n",
    "    * Recognise and/or normalise temporal expressions, e.g. \"tomorrow morning at 8\" -> \"2016-11-26 08:00:00\"\n",
    "* **Event** Extraction:\n",
    "    * Recognise events, typically consisting of entities and relations between them at a point in time and place, e.g. an election"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Relation Extraction\n",
    "\n",
    "Task of extracting **semantic relations between arguments**\n",
    "* Arguments are entities\n",
    "    * general concepts such as \"a company\" (ORG), \"a person\" (PER)\n",
    "    * instances of such concepts (e.g. \"Microsoft\", \"Bill Gates\"), which are called proper names or named entitites (NEs)\n",
    "* Relation extraction builds on the task of named entity recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Relation extraction is relevant for many high-level NLP tasks, such as\n",
    "* for question answering, where users ask questions such as \"Who founded Microsoft?\",\n",
    "* for information retrieval, which often relies on large collections of structured information as background data, and\n",
    "* for text and data mining, where larger patterns in relations between concepts are discovered, e.g. temporal patterns about startups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Relation Extraction as Structured Prediction\n",
    "We can formalise relation extraction as an instance of [structured prediction](/template/statnlpbook/02_methods/00_structuredprediction)\n",
    "* The input space $\\mathcal{X}$ are pairs of arguments $\\mathcal{E}$ and supporting texts $\\mathcal{S}$ those arguments appear in\n",
    "* The output space $\\mathcal{Y}$ is a set of relation labels such as $\\Ys=\\{ \\text{founder-of},\\text{employee-at},\\text{professor-at},\\text{NONE}\\}$. \n",
    "* The goal is to define a model \\\\(s_{\\params}(\\x,y)\\\\) that assigns high *scores* to the label $\\mathcal{y}$ that fits the arguments and supporting text $\\mathcal{x}$, and lower scores otherwise. \n",
    "* The model will be parametrized by \\\\(\\params\\\\), and these parameters we will learn from some training set of $\\mathcal{x,y}$ pairs\n",
    "* When we need to classify input  instances $\\mathcal{x}$ consisting again of pairs of arguments and supporting texts, we have to solve the maximization problem $\\argmax_y s_{\\params}(\\x,y)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Relation Extraction Approaches\n",
    "* **Pattern-Based** Relation Extraction:\n",
    "    * Extract relations via manually defined textual pattern matching\n",
    "* **Bootstrapping**:\n",
    "    * Learn to extract relations via manually defined textual patterns, and use those to find more patterns and so forth, iteratively\n",
    "* **Supervised** Relation Extraction:\n",
    "    * Train a supervised model, from manually labelled training examples, to extract relations\n",
    "* **Distantly Supervised** Relation Extraction:\n",
    "    * Automatically annotate training data for supervised relation extraction, based on entries in a knowledge base\n",
    "* **Universal Schema** Relation Extraction:\n",
    "    * Model relation types and their surface forms in the same space, possible method for combining pattern-based, supervised and distantly supervised relation extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Relation Extraction Example\n",
    "* Extracting \"method used for task\" relations from sentences in computer science publications\n",
    "* The first step would normally be to detection named entities, i.e. to determine tose pairs of arguments $\\mathcal{E}$. For simplicity, our training data already contains those annotations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Pattern-Based Extraction\n",
    "* The simplest relation extraction model defines a set of textual patterns for each relation and then assigns labels to entity pairs whose sentences match that pattern. \n",
    "* The training data consists of entity pairs $\\mathcal{E}$, patterns $A$ and labels $Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Background Material\n",
    "\n",
    "* Jurafky, Dan and Martin, James H. (2016). Speech and Language Processing, Chapter 21 (Information Extraction): https://web.stanford.edu/~jurafsky/slp3/21.pdf\n",
    "\n",
    "* Riedel, Sebastian and Yao, Limin and McCallum, Andrew and Marlin, Benjamin M. (2013). Extraction with Matrix Factorization and Universal Schemas. Proceedings of NAACL.  http://www.aclweb.org/anthology/N13-1008"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
